status = error
name = PropertiesConfig

# Console appender
appender.console.type = Console
appender.console.name = STDOUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# File appender (optional â€” define if you want logs to a file too)
appender.file.type = File
appender.file.name = LOGFILE
appender.file.fileName = logs/sbdl.log
appender.file.layout.type = PatternLayout
appender.file.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# Root logger
rootLogger.level = warn
rootLogger.appenderRefs = stdout
rootLogger.appenderRef.stdout.ref = STDOUT

# Application logger
logger.sbdl.name = sbdl
logger.sbdl.level = info
logger.sbdl.additivity = false
logger.sbdl.appenderRefs = stdout, file
logger.sbdl.appenderRef.stdout.ref = STDOUT
logger.sbdl.appenderRef.file.ref = LOGFILE

# Spark and related loggers
logger.spark_repl_main.name = org.apache.spark.repl.Main
logger.spark_repl_main.level = warn

logger.spark_jetty.name = org.spark_project.jetty
logger.spark_jetty.level = warn

logger.spark_jetty_lifecycle.name = org.spark_project.jetty.util.component.AbstractLifeCycle
logger.spark_jetty_lifecycle.level = error

logger.spark_expr_typer.name = org.apache.spark.repl.SparkIMain$exprTyper
logger.spark_expr_typer.level = info

logger.spark_ilooop.name = org.apache.spark.repl.SparkILoop$SparkILoopInterpreter
logger.spark_ilooop.level = info

logger.parquet1.name = org.apache.parquet
logger.parquet1.level = error

logger.parquet2.name = parquet
logger.parquet2.level = error

logger.hive_handler.name = org.apache.hadoop.hive.metastore.RetryingHMSHandler
logger.hive_handler.level = fatal

logger.hive_registry.name = org.apache.hadoop.hive.ql.exec.FunctionRegistry
logger.hive_registry.level = error
